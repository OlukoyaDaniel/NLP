{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and opening the necessary files needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "results = open(\"result.txt\", \"w+\")\n",
    "results.truncate(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that takes a sentence as a parameter and return the class in which it falls into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(sentence):\n",
    "    \n",
    "    #opening the various text files and storing the data in lists\n",
    "    with open('vocabulary.txt') as v:\n",
    "        vocabulary = v.readlines()\n",
    "        vocabulary = [x.strip('\\n') for x in vocabulary]\n",
    "\n",
    "    with open('documents.txt') as d:\n",
    "        documents = d.readlines()\n",
    "        documents = [x.strip('\\n') for x in documents]\n",
    "\n",
    "    with open('positive_documents.txt') as pd:\n",
    "        positive_documents = pd.readlines()\n",
    "        positive_documents = [x.strip('\\n') for x in positive_documents]\n",
    "\n",
    "    with open('negative_documents.txt') as nd:\n",
    "        negative_documents = nd.readlines()\n",
    "        negative_documents = [x.strip('\\n') for x in negative_documents]\n",
    "\n",
    "    with open('positive_words.txt') as pw:\n",
    "        positive_words = pw.readlines()\n",
    "        positive_words = [x.strip('\\n') for x in positive_words]\n",
    "\n",
    "    with open('negative_words.txt') as nw:\n",
    "        negative_words = nw.readlines()\n",
    "        negative_words = [x.strip('\\n') for x in negative_words]\n",
    "\n",
    "    #Getting the total number of documents\n",
    "    number_of_documents = len(documents)\n",
    "    \n",
    "    #Getting the number of positive documents\n",
    "    number_of_all_pdocs = len(positive_documents)\n",
    "    \n",
    "    #Getting the number of negative documents\n",
    "    number_of_all_ndocs = len(negative_documents)\n",
    "\n",
    "    #Calculating the log prior for the positive class\n",
    "    positive_logprior = number_of_all_pdocs / number_of_documents\n",
    "    \n",
    "    #Calculating the log prior for the negative class\n",
    "    negative_logprior = number_of_all_ndocs / number_of_documents\n",
    "\n",
    "    #dictionary to store the data that would be retrieved from a csv\n",
    "    trained_data = dict()\n",
    "\n",
    "    #reading data in from a csv and wrting them into the trained_data dictionary\n",
    "    with open('Word_Likelihood.csv', mode='r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            if line_count == 0:\n",
    "                line_count += 1\n",
    "            trained_data[row[\"word\"]] = {'word': row['word'], 'positive': row[\"positive\"], 'negative': row[\"negative\"],\n",
    "                                         'count': row[\"word_count\"]}\n",
    "            line_count += 1\n",
    "\n",
    "    text = sentence.replace(\"-\", '\\n').replace(\";\", '\\n').replace(\":\", '\\n').replace(\"/\", '\\n').replace(\"%\",\n",
    "                                                                                                        '\\n').replace(\n",
    "        \"&\", '\\n').replace(\"*\", '\\n').strip('\\n').replace('.', '').replace('!', '').replace('\"', '').replace(\")\",\n",
    "                                                                                                             '').replace(\n",
    "        \"(\",\n",
    "        '').replace(\n",
    "        \"?\", '').replace(\",\", '').replace(\"$\", '').replace('\"', '').replace('”', '').replace('“', '')\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    pdoc_probability = 0\n",
    "    ndoc_probability = 0\n",
    "\n",
    "    # P(doc | class) * P(class)\n",
    "    for t in text:\n",
    "        if t.lower() in trained_data:\n",
    "            d = trained_data[t.lower()]\n",
    "            pdoc_probability += (float(d['positive']) * positive_logprior)\n",
    "        else:\n",
    "            prob = (1 / (len(positive_words) + len(trained_data))) * positive_logprior\n",
    "            pdoc_probability += prob\n",
    "\n",
    "    for t in text:\n",
    "        if t.lower() in trained_data:\n",
    "            d = trained_data[t.lower()]\n",
    "            ndoc_probability += (float(d['negative']) * negative_logprior)\n",
    "\n",
    "        else:\n",
    "            prob = (1 / (len(negative_words) + len(trained_data))) * negative_logprior\n",
    "            ndoc_probability += prob\n",
    "\n",
    "    if pdoc_probability > ndoc_probability:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the class of text that would be passed in from a text file and ouputing it into a results file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(text_file):\n",
    "    \n",
    "    with open(text_file) as t:\n",
    "        file = t.readlines()\n",
    "        file = [\n",
    "            x.replace(\"-\", '\\n').replace(\":\", '\\n').replace(\";\", '\\n').replace(\"*\", '\\n').replace(\"%\", '\\n').replace(\n",
    "                \"&\", '\\n').replace(\"/\", '\\n').strip('\\n').replace('.', '').replace('!', '').replace('\"', '').replace(\n",
    "                \")\", '').replace(\"(\",\n",
    "                                 '').replace(\n",
    "                \"?\", '').replace(\",\", '') for x in file]\n",
    "\n",
    "    for doc in file:\n",
    "        result = test(str(doc))\n",
    "        results.write(str(result) + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    text_file=input('Please enter the filename with the (.txt) extension: ')\n",
    "    print('This might take about 2 minutes')\n",
    "    main(str(text_file))\n",
    "    print('Process completed check the results.txt file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
